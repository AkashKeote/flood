{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dacb2d93-3c11-4423-b708-f2dcbbd82e95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: xgboost in c:\\users\\anshika\\anaconda3\\lib\\site-packages (3.0.4)\n",
      "Requirement already satisfied: numpy in c:\\users\\anshika\\anaconda3\\lib\\site-packages (from xgboost) (1.26.4)\n",
      "Requirement already satisfied: scipy in c:\\users\\anshika\\anaconda3\\lib\\site-packages (from xgboost) (1.13.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4613dcf9-621d-4aba-9287-90957b0190b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: xgboost in c:\\users\\anshika\\anaconda3\\lib\\site-packages (3.0.4)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\anshika\\anaconda3\\lib\\site-packages (1.4.2)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\anshika\\anaconda3\\lib\\site-packages (3.8.4)\n",
      "Requirement already satisfied: numpy in c:\\users\\anshika\\anaconda3\\lib\\site-packages (from xgboost) (1.26.4)\n",
      "Requirement already satisfied: scipy in c:\\users\\anshika\\anaconda3\\lib\\site-packages (from xgboost) (1.13.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\anshika\\anaconda3\\lib\\site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\anshika\\anaconda3\\lib\\site-packages (from scikit-learn) (2.2.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\anshika\\anaconda3\\lib\\site-packages (from matplotlib) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\anshika\\anaconda3\\lib\\site-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\anshika\\anaconda3\\lib\\site-packages (from matplotlib) (4.51.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\anshika\\anaconda3\\lib\\site-packages (from matplotlib) (1.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\anshika\\anaconda3\\lib\\site-packages (from matplotlib) (23.2)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\anshika\\anaconda3\\lib\\site-packages (from matplotlib) (10.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\anshika\\anaconda3\\lib\\site-packages (from matplotlib) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\anshika\\anaconda3\\lib\\site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\anshika\\anaconda3\\lib\\site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install xgboost scikit-learn matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f3276068-d0ff-4cc8-83be-d3720212829b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  DATE  Ward Code  Latitude  Longitude  Rainfall_mm  \\\n",
      "0     01-06-2023 00:00         18   18.9151    72.8141     0.000000   \n",
      "1     02-06-2023 00:00         18   18.9151    72.8141     0.000000   \n",
      "2     03-06-2023 00:00         18   18.9151    72.8141     0.000000   \n",
      "3     04-06-2023 00:00         18   18.9151    72.8141     6.610472   \n",
      "4     05-06-2023 00:00         18   18.9151    72.8141     0.000000   \n",
      "...                ...        ...       ...        ...          ...   \n",
      "9265  25-08-2023 00:00         40   19.1728    72.9473     8.107118   \n",
      "9266  26-08-2023 00:00         40   19.1728    72.9473    14.391339   \n",
      "9267  27-08-2023 00:00         40   19.1728    72.9473     9.215490   \n",
      "9268  28-08-2023 00:00         40   19.1728    72.9473     9.081804   \n",
      "9269  29-08-2023 00:00         40   19.1728    72.9473     0.000000   \n",
      "\n",
      "      Discharge_m3s  Elevation  Land Use Classes  Population Flood-risk_level  \\\n",
      "0          1.250000        6.0                 3      185000         Moderate   \n",
      "1          1.250000        6.0                 3      185000         Moderate   \n",
      "2          1.250000        6.0                 3      185000         Moderate   \n",
      "3          1.250000        6.0                 3      185000         Moderate   \n",
      "4          1.281250        6.0                 3      185000         Moderate   \n",
      "...             ...        ...               ...         ...              ...   \n",
      "9265       2.015625        7.0                31      640000             High   \n",
      "9266       2.078125        7.0                31      640000             High   \n",
      "9267       2.234375        7.0                31      640000             High   \n",
      "9268       2.109375        7.0                31      640000             High   \n",
      "9269       1.859375        7.0                31      640000             High   \n",
      "\n",
      "      ...  Runoff equivalent  Soil Wetness Index  Rainfall_Intensity_mm_hr  \\\n",
      "0     ...           0.000000            0.456860                  0.000000   \n",
      "1     ...           0.000000            0.455249                  0.000000   \n",
      "2     ...           0.000000            0.454303                  0.000000   \n",
      "3     ...           0.324249            0.455974                  0.275436   \n",
      "4     ...           0.000000            0.455732                  0.000000   \n",
      "...   ...                ...                 ...                       ...   \n",
      "9265  ...           3.663483            0.829891                  0.337797   \n",
      "9266  ...           4.403671            0.830336                  0.599639   \n",
      "9267  ...           3.611923            0.828859                  0.383979   \n",
      "9268  ...           2.784760            0.826629                  0.378409   \n",
      "9269  ...           1.815750            0.811766                  0.000000   \n",
      "\n",
      "      Rainfall Days Count  Longest rainfall _days  Distance_to_water_m  \\\n",
      "0                      28                       5                    9   \n",
      "1                      28                       5                    9   \n",
      "2                      28                       5                    9   \n",
      "3                      28                       5                    9   \n",
      "4                      28                       5                    9   \n",
      "...                   ...                     ...                  ...   \n",
      "9265                   32                       8                   10   \n",
      "9266                   32                       8                   10   \n",
      "9267                   32                       8                   10   \n",
      "9268                   32                       8                   10   \n",
      "9269                   32                       8                   10   \n",
      "\n",
      "      Soil Type  Built_up%  True_nearest_distance_m  true_conditions_count  \n",
      "0             4       90.0                  3921.69                      1  \n",
      "1             4       90.0                  3921.69                      1  \n",
      "2             4       90.0                  3921.69                      1  \n",
      "3             4       90.0                  3921.69                      1  \n",
      "4             4       90.0                  3921.69                      1  \n",
      "...         ...        ...                      ...                    ...  \n",
      "9265          4       90.0                   112.03                      3  \n",
      "9266          4       90.0                   112.03                      3  \n",
      "9267          4       90.0                   112.03                      3  \n",
      "9268          4       90.0                   112.03                      3  \n",
      "9269          4       90.0                   112.03                      3  \n",
      "\n",
      "[9270 rows x 23 columns]\n",
      "✅ Preprocessing complete\n",
      "New training set shape: (4500, 15)\n",
      "New test set shape: (4770, 15)\n",
      "\n",
      "Training Voting Ensemble Model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anshika\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [04:25:50] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Voting Ensemble Model trained successfully.\n",
      "\n",
      "Training Accuracy for Voting Ensemble: 0.8438\n",
      "Validation Accuracy for Voting Ensemble (Cross-Validation): 0.8271\n",
      "✅ Test Accuracy for Voting Ensemble: 0.8193\n",
      "Classification Report on Test Data:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "        High       0.84      0.86      0.85      2882\n",
      "         Low       1.00      1.00      1.00      1111\n",
      "    Moderate       0.44      0.39      0.42       777\n",
      "\n",
      "    accuracy                           0.82      4770\n",
      "   macro avg       0.76      0.75      0.76      4770\n",
      "weighted avg       0.81      0.82      0.82      4770\n",
      "\n",
      "\n",
      "✅ Final model and encoders saved successfully.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import joblib\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.utils import class_weight\n",
    "\n",
    "# Set the matplotlib backend to Agg to prevent TclError\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "\n",
    "# -------------------------------\n",
    "# STEP 1: Load and Clean Dataset\n",
    "# -------------------------------\n",
    "df = pd.read_csv(\"final_flood_classification data.csv\")\n",
    "\n",
    "# Correct the column name with a leading space\n",
    "if ' Population' in df.columns:\n",
    "    df.rename(columns={' Population': 'Population'}, inplace=True)\n",
    "if 'Discharge (m³/s)' in df.columns:\n",
    "    df.rename(columns={'Discharge (m³/s)': 'Discharge_m3s'}, inplace=True)\n",
    "\n",
    "# Replace '--' with NaN across the dataset\n",
    "df = df.replace(\"--\", np.nan)\n",
    "\n",
    "# -------------------------------\n",
    "# STEP 2: Drop Unnecessary Columns\n",
    "# -------------------------------\n",
    "df = df.drop(columns=[\"Areas\", \"Nearest Station\", \"Drainage_properties\", \"Drainage_line_id\"], errors='ignore')\n",
    "\n",
    "# -------------------------------\n",
    "# STEP 3: Handle Categorical Variables Safely\n",
    "# -------------------------------\n",
    "cat_cols = [\"Ward Code\", \"Land Use Classes\", \"Flood_occured\", \"Road Density_m\", \"Monitoring_required\", \"Soil Type\"]\n",
    "for col in cat_cols:\n",
    "    if col in df.columns:\n",
    "        df[col] = df[col].astype(str).fillna(\"Unknown\")\n",
    "        le = LabelEncoder()\n",
    "        df[col] = le.fit_transform(df[col])\n",
    "    else:\n",
    "        print(f\"Warning: Column '{col}' not found in DataFrame.\")\n",
    "\n",
    "# -------------------------------\n",
    "# STEP 4: Handle Numeric Columns (Fill Missing)\n",
    "# -------------------------------\n",
    "for col in df.select_dtypes(include=['float64', 'int64']).columns:\n",
    "    df[col] = pd.to_numeric(df[col], errors='coerce').fillna(df[col].median())\n",
    "\n",
    "# -------------------------------\n",
    "# STEP 5: Feature/Target Separation and Encoding\n",
    "# -------------------------------\n",
    "# IMPORTANT: Drop all features that cause data leakage.\n",
    "features_to_drop = [\n",
    "    \"Flood-risk_level\",      # The target variable itself\n",
    "    \"DATE\",                  # Irrelevant for prediction\n",
    "    \"true_conditions_count\", # Highly correlated (leaky)\n",
    "    \"Soil Wetness Index\",    # Highly correlated (leaky)\n",
    "    \"Runoff equivalent\",     # Highly correlated (leaky)\n",
    "    \"Discharge_m3s\",         # Highly correlated (leaky)\n",
    "    \"Flood_occured\",         # Likely a direct cause of flood-risk\n",
    "    \"Monitoring_required\",   # Likely decided based on flood-risk\n",
    "    \"Drainage_properties\",\n",
    "    \"Drainage_line_id\"\n",
    "]\n",
    "\n",
    "X = df.drop(columns=features_to_drop, errors='ignore')\n",
    "y = df[\"Flood-risk_level\"]\n",
    "\n",
    "# Encode the target variable `y` into numerical values\n",
    "target_encoder = LabelEncoder()\n",
    "y = target_encoder.fit_transform(y)\n",
    "print(df)\n",
    "# -------------------------------\n",
    "# STEP 6: Train-Test Split with a fixed size\n",
    "# -------------------------------\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, train_size=4500, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(\"✅ Preprocessing complete\")\n",
    "print(\"New training set shape:\", X_train.shape)\n",
    "print(\"New test set shape:\", X_test.shape)\n",
    "\n",
    "# -------------------------------\n",
    "# STEP 7: Scale Numeric Columns\n",
    "# -------------------------------\n",
    "num_cols = X_train.select_dtypes(include=['float64', 'int64']).columns\n",
    "scaler = StandardScaler()\n",
    "X_train[num_cols] = scaler.fit_transform(X_train[num_cols])\n",
    "X_test[num_cols] = scaler.transform(X_test[num_cols])\n",
    "\n",
    "# -------------------------------\n",
    "# STEP 8: Final Model Training (Voting Ensemble)\n",
    "# -------------------------------\n",
    "print(\"\\nTraining Voting Ensemble Model...\")\n",
    "# Define base models with their best-tuned hyperparameters from previous runs.\n",
    "base_model_rf = RandomForestClassifier(n_estimators=100, max_depth=15, min_samples_leaf=1, min_samples_split=2, class_weight='balanced', random_state=42)\n",
    "base_model_xgb = XGBClassifier(n_estimators=100, learning_rate=0.2, max_depth=7, subsample=1.0, use_label_encoder=False, eval_metric='mlogloss', random_state=42)\n",
    "\n",
    "# Pass the correct sample_weights for XGBoost\n",
    "sample_weights_xgb = class_weight.compute_sample_weight(class_weight='balanced', y=y_train)\n",
    "\n",
    "# Train the base models individually to get their trained state\n",
    "base_model_rf.fit(X_train, y_train)\n",
    "base_model_xgb.fit(X_train, y_train, sample_weight=sample_weights_xgb)\n",
    "\n",
    "# Create the Voting Ensemble model\n",
    "ensemble_model = VotingClassifier(\n",
    "    estimators=[\n",
    "        ('rf', base_model_rf),\n",
    "        ('xgb', base_model_xgb)\n",
    "    ],\n",
    "    voting='soft',\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "ensemble_model.fit(X_train, y_train)\n",
    "print(\"✅ Voting Ensemble Model trained successfully.\")\n",
    "\n",
    "\n",
    "# -------------------------------\n",
    "# STEP 9: Evaluate the Final Model\n",
    "# -------------------------------\n",
    "def evaluate_model(X_train, y_train, X_test, y_test, model, name):\n",
    "    y_train_pred = model.predict(X_train)\n",
    "    train_acc = accuracy_score(y_train, y_train_pred)\n",
    "    # This line prints the Training Accuracy\n",
    "    print(f\"\\nTraining Accuracy for {name}: {train_acc:.4f}\")\n",
    "    \n",
    "    # Calculate validation accuracy using cross-validation\n",
    "    cv_scores = cross_val_score(model, X_train, y_train, cv=5, n_jobs=-1, scoring='accuracy')\n",
    "    validation_acc = np.mean(cv_scores)\n",
    "    # This line prints the Validation Accuracy\n",
    "    print(f\"Validation Accuracy for {name} (Cross-Validation): {validation_acc:.4f}\")\n",
    "    \n",
    "    y_pred = model.predict(X_test)\n",
    "    test_acc = accuracy_score(y_test, y_pred)\n",
    "    # This line prints the Test Accuracy\n",
    "    print(f\"✅ Test Accuracy for {name}: {test_acc:.4f}\")\n",
    "    \n",
    "    print(\"Classification Report on Test Data:\\n\", classification_report(y_test, y_pred, zero_division=0, target_names=target_encoder.classes_))\n",
    "    \n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    plt.figure(figsize=(6,4))\n",
    "    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=target_encoder.classes_, yticklabels=target_encoder.classes_)\n",
    "    plt.title(f\"{name} - Confusion Matrix\")\n",
    "    plt.xlabel(\"Predicted\")\n",
    "    plt.ylabel(\"Actual\")\n",
    "    plt.savefig(f\"{name}_confusion_matrix.png\")\n",
    "    plt.close()\n",
    "\n",
    "evaluate_model(X_train, y_train, X_test, y_test, ensemble_model, \"Voting Ensemble\")\n",
    "\n",
    "# -------------------------------\n",
    "# STEP 10: Save Final Model\n",
    "# -------------------------------\n",
    "joblib.dump(ensemble_model, 'ensemble_model.joblib')\n",
    "joblib.dump(scaler, 'scaler.joblib')\n",
    "joblib.dump(target_encoder, 'target_encoder.joblib')\n",
    "\n",
    "print(\"\\n✅ Final model and encoders saved successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "42343d3a-1271-41c2-a0b8-9a93f26a3979",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total unique wards: 41\n",
      "Total unique areas: 102\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv(\"final_flood_classification data.csv\")\n",
    "\n",
    "# Get the count of unique wards and areas\n",
    "unique_wards = df['Ward Code'].nunique()\n",
    "unique_areas = df['Areas'].nunique()\n",
    "\n",
    "print(f\"Total unique wards: {unique_wards}\")\n",
    "print(f\"Total unique areas: {unique_areas}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e45f3cb-71de-49d2-98cf-5542c7a7b8e9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
